{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1420e73-45fc-427f-b0b8-fc015e3edaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import IPython\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "781508ab-ec8e-4fd5-903d-021cdf6473ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "from ipywidgets import interact, interactive\n",
    "# from plotting_functions import *\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import (\n",
    "    ColumnTransformer,\n",
    "    make_column_transformer\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78169ef6-7192-4861-8358-da1f16105334",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"../../data/raw/abalone.data\",\n",
    "    names=[\n",
    "        \"Sex\",\n",
    "        \"Length\",\n",
    "        \"Diameter\",\n",
    "        \"Height\",\n",
    "        \"Whole weight\",\n",
    "        \"Shucked weight\",\n",
    "        \"Viscera weight\",\n",
    "        \"Shell weight\",\n",
    "        \"Rings\",\n",
    "    ],\n",
    "    header=0,\n",
    ")\n",
    "\n",
    "# Add a classification target columns. If rings > 11, then classified as old\n",
    "df[\"Is old\"] = np.where(df[\"Rings\"] > 11, \"old\", \"young\")\n",
    "df.head()\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=123)\n",
    "X_train = train_df.drop(columns=['Is old'])\n",
    "X_test = test_df.drop(columns=['Is old'])\n",
    "y_train = train_df['Is old']\n",
    "y_test = test_df['Is old']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2a561fe-89bb-4ec7-bf6c-4798f828fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column transformer for analysis pipeline\n",
    "\n",
    "categorical_feature = ['Sex']\n",
    "numerical_features = ['Length', 'Diameter', 'Height', 'Whole weight', \n",
    "'Shucked weight', 'Viscera weight', 'Shell weight']\n",
    "target = 'Is old'\n",
    "drop_feature = ['Rings']\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), numerical_features),\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\", sparse=False), \n",
    "     categorical_feature),\n",
    "    (\"drop\", drop_feature),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2793b850-f09a-4420-a72c-8242201827cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maoli\\miniconda3\\envs\\571\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 7 is smaller than n_iter=10. Running 7 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('columntransformer',\n",
       "                                              ColumnTransformer(transformers=[('standardscaler',\n",
       "                                                                               StandardScaler(),\n",
       "                                                                               ['Length',\n",
       "                                                                                'Diameter',\n",
       "                                                                                'Height',\n",
       "                                                                                'Whole '\n",
       "                                                                                'weight',\n",
       "                                                                                'Shucked '\n",
       "                                                                                'weight',\n",
       "                                                                                'Viscera '\n",
       "                                                                                'weight',\n",
       "                                                                                'Shell '\n",
       "                                                                                'weight']),\n",
       "                                                                              ('onehotencoder',\n",
       "                                                                               OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                             sparse=False),\n",
       "                                                                               ['Sex']),\n",
       "                                                                              ('drop',\n",
       "                                                                               'drop',\n",
       "                                                                               ['Rings'])])),\n",
       "                                             ('logisticregression',\n",
       "                                              LogisticRegression(max_iter=2000))]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'logisticregression__C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])},\n",
       "                   random_state=123)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model by using random search CV\n",
    "\n",
    "lr = LogisticRegression(max_iter=2000)\n",
    "pipe = make_pipeline(preprocessor, lr)\n",
    "param_grid = {\"logisticregression__C\": 10.0 ** np.arange(-3, 4)}\n",
    "\n",
    "random_search = RandomizedSearchCV(pipe,\n",
    "                                   param_distributions = param_grid,\n",
    "                                   n_jobs = -1,\n",
    "                                   n_iter = 10,\n",
    "                                   cv = 5,\n",
    "                                   random_state = 123)\n",
    "random_search.fit(pd.DataFrame(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7da14a7-3425-4056-8934-401596289e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the training results in a data frame\n",
    "\n",
    "train_results = pd.DataFrame(random_search.cv_results_)[\n",
    "    [   \"mean_test_score\",\n",
    "        \"param_logisticregression__C\",\n",
    "        \"mean_fit_time\",\n",
    "        \"rank_test_score\",\n",
    "    ]\n",
    "].set_index(\"rank_test_score\").sort_index().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0801f74-8a26-4e51-9f8f-d06862a88b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8421052631578947"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick the final model and predict test data\n",
    "\n",
    "best_c = train_results.iloc[1, 0]\n",
    "\n",
    "pipe_best = make_pipeline(preprocessor, LogisticRegression(C = best_c, max_iter=2000))\n",
    "pipe_best.fit(X_train, y_train)\n",
    "\n",
    "pipe_best.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf8316b-ef03-45cb-bcd9-ba4237cd7aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:571]",
   "language": "python",
   "name": "conda-env-571-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
